{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65b4ab05-18e9-4542-ab6e-084cb36e8498",
   "metadata": {},
   "source": [
    "# DATA PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bbd4405-8b4b-40ed-9f69-eabe7fae9d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "train_path = \"UNSW_NB15_training-set.csv\"\n",
    "test_path = \"UNSW_NB15_testing-set.csv\"\n",
    "\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_test = pd.read_csv(test_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbba8d0-bad0-446d-a2fc-4f4eacc5c275",
   "metadata": {},
   "source": [
    "HANDLING MISSING VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9c2c8fc-cc5d-4298-814c-91e415ea7d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle missing values\n",
    "def handle_missing_values(df):\n",
    "    # Step 1: Replace potential placeholders for missing values ('-', 'NA', 'N/A', etc.)\n",
    "    df.replace(['-', 'NA', 'N/A', 'unknown', 'null', 'NULL'], pd.NA, inplace=True)\n",
    "    \n",
    "    # Step 2: Drop columns with >40% missing data\n",
    "    missing_percent = (df.isnull().sum() / len(df)) * 100\n",
    "    cols_to_drop = missing_percent[missing_percent > 40].index\n",
    "    df.drop(columns=cols_to_drop, inplace=True)\n",
    "    \n",
    "    # Step 3: Drop rows with >30% missing data\n",
    "    df.dropna(thresh=len(df.columns) * 0.7, inplace=True)\n",
    "    \n",
    "    # Step 4: Identify numerical and categorical features\n",
    "    num_cols = df.select_dtypes(include=['number']).columns\n",
    "    cat_cols = df.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    # Step 5: Apply Median Imputation for Numerical Features\n",
    "    for col in num_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "    # Step 6: Apply Dynamic Imputation for Categorical Features\n",
    "    for col in cat_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            if df[col].nunique() < 10:  # Few unique categories → Use Mode\n",
    "                df[col] = df[col].fillna(df[col].mode()[0])\n",
    "            else:  # Many unique categories → Use 'Unknown'\n",
    "                df[col] = df[col].fillna(\"Unknown\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ad94ea-c875-44dd-b4cf-7429242be6f9",
   "metadata": {},
   "source": [
    "Saving the new dataset after handling missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d33d24d9-b19f-431e-8765-033c0bea3c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Missing values handled and datasets saved to new files!\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to training and testing datasets\n",
    "df_train_cleaned = handle_missing_values(df_train)\n",
    "df_test_cleaned = handle_missing_values(df_test)\n",
    "\n",
    "# Save the cleaned datasets into new files\n",
    "df_train_cleaned.to_csv(\"UNSW_NB15_training_cleaned_new.csv\", index=False)\n",
    "df_test_cleaned.to_csv(\"UNSW_NB15_testing_cleaned_new.csv\", index=False)\n",
    "\n",
    "print(\"✅ Missing values handled and datasets saved to new files!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f058e64c-0219-47d3-b36d-b7d6a05c38b4",
   "metadata": {},
   "source": [
    "Checking how well we handled missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e553771a-04ea-47a5-b3a6-49173aba31c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training dataset - Total missing values: 47153\n",
      "Missing values per column in original training dataset:\n",
      "id                       0\n",
      "dur                      0\n",
      "proto                    0\n",
      "service              47153\n",
      "state                    0\n",
      "spkts                    0\n",
      "dpkts                    0\n",
      "sbytes                   0\n",
      "dbytes                   0\n",
      "rate                     0\n",
      "sttl                     0\n",
      "dttl                     0\n",
      "sload                    0\n",
      "dload                    0\n",
      "sloss                    0\n",
      "dloss                    0\n",
      "sinpkt                   0\n",
      "dinpkt                   0\n",
      "sjit                     0\n",
      "djit                     0\n",
      "swin                     0\n",
      "stcpb                    0\n",
      "dtcpb                    0\n",
      "dwin                     0\n",
      "tcprtt                   0\n",
      "synack                   0\n",
      "ackdat                   0\n",
      "smean                    0\n",
      "dmean                    0\n",
      "trans_depth              0\n",
      "response_body_len        0\n",
      "ct_srv_src               0\n",
      "ct_state_ttl             0\n",
      "ct_dst_ltm               0\n",
      "ct_src_dport_ltm         0\n",
      "ct_dst_sport_ltm         0\n",
      "ct_dst_src_ltm           0\n",
      "is_ftp_login             0\n",
      "ct_ftp_cmd               0\n",
      "ct_flw_http_mthd         0\n",
      "ct_src_ltm               0\n",
      "ct_srv_dst               0\n",
      "is_sm_ips_ports          0\n",
      "attack_cat               0\n",
      "label                    0\n",
      "dtype: int64\n",
      "\n",
      "Original testing dataset - Total missing values: 94168\n",
      "Missing values per column in original testing dataset:\n",
      "id                       0\n",
      "dur                      0\n",
      "proto                    0\n",
      "service              94168\n",
      "state                    0\n",
      "spkts                    0\n",
      "dpkts                    0\n",
      "sbytes                   0\n",
      "dbytes                   0\n",
      "rate                     0\n",
      "sttl                     0\n",
      "dttl                     0\n",
      "sload                    0\n",
      "dload                    0\n",
      "sloss                    0\n",
      "dloss                    0\n",
      "sinpkt                   0\n",
      "dinpkt                   0\n",
      "sjit                     0\n",
      "djit                     0\n",
      "swin                     0\n",
      "stcpb                    0\n",
      "dtcpb                    0\n",
      "dwin                     0\n",
      "tcprtt                   0\n",
      "synack                   0\n",
      "ackdat                   0\n",
      "smean                    0\n",
      "dmean                    0\n",
      "trans_depth              0\n",
      "response_body_len        0\n",
      "ct_srv_src               0\n",
      "ct_state_ttl             0\n",
      "ct_dst_ltm               0\n",
      "ct_src_dport_ltm         0\n",
      "ct_dst_sport_ltm         0\n",
      "ct_dst_src_ltm           0\n",
      "is_ftp_login             0\n",
      "ct_ftp_cmd               0\n",
      "ct_flw_http_mthd         0\n",
      "ct_src_ltm               0\n",
      "ct_srv_dst               0\n",
      "is_sm_ips_ports          0\n",
      "attack_cat               0\n",
      "label                    0\n",
      "dtype: int64\n",
      "\n",
      "Cleaned training dataset - Total missing values: 0\n",
      "Missing values per column in cleaned training dataset:\n",
      "id                   0\n",
      "dur                  0\n",
      "proto                0\n",
      "state                0\n",
      "spkts                0\n",
      "dpkts                0\n",
      "sbytes               0\n",
      "dbytes               0\n",
      "rate                 0\n",
      "sttl                 0\n",
      "dttl                 0\n",
      "sload                0\n",
      "dload                0\n",
      "sloss                0\n",
      "dloss                0\n",
      "sinpkt               0\n",
      "dinpkt               0\n",
      "sjit                 0\n",
      "djit                 0\n",
      "swin                 0\n",
      "stcpb                0\n",
      "dtcpb                0\n",
      "dwin                 0\n",
      "tcprtt               0\n",
      "synack               0\n",
      "ackdat               0\n",
      "smean                0\n",
      "dmean                0\n",
      "trans_depth          0\n",
      "response_body_len    0\n",
      "ct_srv_src           0\n",
      "ct_state_ttl         0\n",
      "ct_dst_ltm           0\n",
      "ct_src_dport_ltm     0\n",
      "ct_dst_sport_ltm     0\n",
      "ct_dst_src_ltm       0\n",
      "is_ftp_login         0\n",
      "ct_ftp_cmd           0\n",
      "ct_flw_http_mthd     0\n",
      "ct_src_ltm           0\n",
      "ct_srv_dst           0\n",
      "is_sm_ips_ports      0\n",
      "attack_cat           0\n",
      "label                0\n",
      "dtype: int64\n",
      "\n",
      "Cleaned testing dataset - Total missing values: 0\n",
      "Missing values per column in cleaned testing dataset:\n",
      "id                   0\n",
      "dur                  0\n",
      "proto                0\n",
      "state                0\n",
      "spkts                0\n",
      "dpkts                0\n",
      "sbytes               0\n",
      "dbytes               0\n",
      "rate                 0\n",
      "sttl                 0\n",
      "dttl                 0\n",
      "sload                0\n",
      "dload                0\n",
      "sloss                0\n",
      "dloss                0\n",
      "sinpkt               0\n",
      "dinpkt               0\n",
      "sjit                 0\n",
      "djit                 0\n",
      "swin                 0\n",
      "stcpb                0\n",
      "dtcpb                0\n",
      "dwin                 0\n",
      "tcprtt               0\n",
      "synack               0\n",
      "ackdat               0\n",
      "smean                0\n",
      "dmean                0\n",
      "trans_depth          0\n",
      "response_body_len    0\n",
      "ct_srv_src           0\n",
      "ct_state_ttl         0\n",
      "ct_dst_ltm           0\n",
      "ct_src_dport_ltm     0\n",
      "ct_dst_sport_ltm     0\n",
      "ct_dst_src_ltm       0\n",
      "is_ftp_login         0\n",
      "ct_ftp_cmd           0\n",
      "ct_flw_http_mthd     0\n",
      "ct_src_ltm           0\n",
      "ct_srv_dst           0\n",
      "is_sm_ips_ports      0\n",
      "attack_cat           0\n",
      "label                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Function to check missing values (including placeholders for missing data)\n",
    "def check_missing_values(df):\n",
    "    # Replace potential placeholders for missing values ('-', 'NA', 'N/A', etc.)\n",
    "    df_replaced = df.replace(['-', 'NA', 'N/A', 'unknown', 'null', 'NULL'], pd.NA)\n",
    "    \n",
    "    # Count the total number of missing values in the dataset\n",
    "    missing_values_count = df_replaced.isnull().sum().sum()  # Total number of missing values\n",
    "    missing_values_per_column = df_replaced.isnull().sum()   # Missing values per column\n",
    "    \n",
    "    return missing_values_count, missing_values_per_column\n",
    "\n",
    "# Load the original and cleaned datasets\n",
    "df_train_original = pd.read_csv(train_path)\n",
    "df_test_original = pd.read_csv(test_path)\n",
    "\n",
    "df_train_cleaned = pd.read_csv(\"UNSW_NB15_training_cleaned_new.csv\")\n",
    "df_test_cleaned = pd.read_csv(\"UNSW_NB15_testing_cleaned_new.csv\")\n",
    "\n",
    "# Check missing values in the original datasets\n",
    "train_original_missing_count, train_original_missing_per_column = check_missing_values(df_train_original)\n",
    "test_original_missing_count, test_original_missing_per_column = check_missing_values(df_test_original)\n",
    "\n",
    "# Check missing values in the cleaned datasets\n",
    "train_cleaned_missing_count, train_cleaned_missing_per_column = check_missing_values(df_train_cleaned)\n",
    "test_cleaned_missing_count, test_cleaned_missing_per_column = check_missing_values(df_test_cleaned)\n",
    "\n",
    "# Print results\n",
    "print(f\"Original training dataset - Total missing values: {train_original_missing_count}\")\n",
    "print(f\"Missing values per column in original training dataset:\\n{train_original_missing_per_column}\")\n",
    "print(f\"\\nOriginal testing dataset - Total missing values: {test_original_missing_count}\")\n",
    "print(f\"Missing values per column in original testing dataset:\\n{test_original_missing_per_column}\")\n",
    "\n",
    "print(f\"\\nCleaned training dataset - Total missing values: {train_cleaned_missing_count}\")\n",
    "print(f\"Missing values per column in cleaned training dataset:\\n{train_cleaned_missing_per_column}\")\n",
    "print(f\"\\nCleaned testing dataset - Total missing values: {test_cleaned_missing_count}\")\n",
    "print(f\"Missing values per column in cleaned testing dataset:\\n{test_cleaned_missing_per_column}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0748ce40-271a-4edf-b2c0-1d0824ffa59f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
